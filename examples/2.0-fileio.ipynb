{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d53fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717558b0",
   "metadata": {},
   "source": [
    "# File Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebc8e4",
   "metadata": {},
   "source": [
    "## Create Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fcdafa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files written successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import pyarrow as pa\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.parquet as pq\n",
    "import sqlite3\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "cols = [\"name\", \"apple\", \"orange\", \"banana\"]\n",
    "rows =[\n",
    "    [\"Alice\", 1, 0, 1],\n",
    "    [\"Bob\", 0, 1, 0],\n",
    "    [\"Charlie\", 1, 1, 0],\n",
    "]\n",
    "df = pd.DataFrame(data=rows, columns=cols)\n",
    "\n",
    "def create_sql_text_file(df, path):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"SELECT 1;\\nSELECT 2;\\n\")\n",
    "\n",
    "# Define file formats and corresponding write functions\n",
    "file_formats ={\n",
    "    \"csv\": lambda df, path: df.to_csv(path, index=False),\n",
    "    \"txt\": lambda df, path: df.to_csv(path, index=False, sep='\\t'),\n",
    "    \"text\": lambda df, path: df.to_csv(path, index=False, sep='\\t'),\n",
    "    \"log\": lambda df, path: df.to_csv(path, index=False, sep='\\t'),\n",
    "    \"sql\": create_sql_text_file,  # Use our custom function for SQL text files\n",
    "    \"json\": lambda df, path: df.to_json(path, orient='records', lines=False),\n",
    "    \"yaml\": lambda df, path: yaml.dump(df.to_dict(orient=\"records\"), open(path, \"w\")),\n",
    "    \"yml\": lambda df, path: yaml.dump(df.to_dict(orient=\"records\"), open(path, \"w\")),\n",
    "    \"arrow\": lambda df, path: pa.Table.from_pandas(df.reset_index(drop=True)).to_arrow().to_pybytes(),\n",
    "    \"pickle\": lambda df, path: df.to_pickle(path),\n",
    "    \"pkl\": lambda df, path: df.to_pickle(path),\n",
    "    \"parquet\": lambda df, path: df.to_parquet(path, index=False),\n",
    "    \"feather\": lambda df, path: feather.write_feather(df.reset_index(drop=True), path),\n",
    "}\n",
    "\n",
    "base_path = \"./test_files/test\"\n",
    "os.makedirs(base_path, exist_ok = True)\n",
    "for ext, write_func in file_formats.items():\n",
    "    file_path = f\"{base_path}.{ext}\"\n",
    "    if ext == \"arrow\":\n",
    "        table = pa.Table.from_pandas(df.reset_index(drop=True))\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            feather.write_feather(df.reset_index(drop=True), file_path)\n",
    "    elif ext == \"yaml\" or ext == \"yml\":\n",
    "        with open(file_path, \"w\") as f:\n",
    "            yaml.dump(df.to_dict(orient=\"records\"), f)\n",
    "    else:\n",
    "        write_func(df, file_path)\n",
    "\n",
    "print(\"Files written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f308dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import FileIO as file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18be6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileio_mapping = {\n",
    "#     \"csv\": CSVFileIO,\n",
    "#     \"txt\": TextFileIO,\n",
    "#     \"text\": TextFileIO,\n",
    "#     \"log\": TextFileIO,\n",
    "#     \"sql\": SQLFileIO,\n",
    "#     \"json\": JsonFileIO,\n",
    "#     \"yaml\": YamlFileIO,\n",
    "#     \"yml\": YamlFileIO,\n",
    "#     \"arrow\": ArrowFileIO,\n",
    "#     \"feather\": FeatherFileIO,\n",
    "#     \"parquet\": ParquetFileIO,\n",
    "#     \"pickle\": PickleFileIO,\n",
    "#     \"pkl\": PickleFileIO,\n",
    "# }\n",
    "\n",
    "file_types = [\"csv\",\n",
    "              \"txt\",\n",
    "              \"text\",\n",
    "              \"log\",\n",
    "              \"sql\",\n",
    "              \"json\",\n",
    "              \"yaml\",\n",
    "              \"yml\",\n",
    "              \"arrow\",\n",
    "              \"feather\",\n",
    "              \"parquet\",\n",
    "              \"pickle\",\n",
    "              \"pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv exists: True\n",
      "txt exists: True\n",
      "text exists: True\n",
      "log exists: True\n",
      "sql exists: True\n",
      "json exists: True\n",
      "yaml exists: True\n",
      "yml exists: True\n",
      "arrow exists: True\n",
      "feather exists: True\n",
      "parquet exists: True\n",
      "pickle exists: True\n",
      "pkl exists: True\n"
     ]
    }
   ],
   "source": [
    "for f_type in file_types:\n",
    "    path = f\"./test_files/test.{f_type}\"\n",
    "\n",
    "    # Existence\n",
    "    print(f\"{f_type} exists:\", file_io.fexists(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.csv', 'size': 65, 'type': 'file', 'created': 1756889645.1869767, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1869767, 'ino': 2533274791923254, 'nlink': 1}\n",
      "txt info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.txt', 'size': 65, 'type': 'file', 'created': 1756889645.1869767, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1869767, 'ino': 2814749768633920, 'nlink': 1}\n",
      "text info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.text', 'size': 65, 'type': 'file', 'created': 1756889645.1912436, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1912436, 'ino': 2533274791923270, 'nlink': 1}\n",
      "log info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.log', 'size': 65, 'type': 'file', 'created': 1756889645.1912436, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1912436, 'ino': 1970324838501959, 'nlink': 1}\n",
      "sql info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.sql', 'size': 22, 'type': 'file', 'created': 1756889645.1912436, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1912436, 'ino': 2251799815212617, 'nlink': 1}\n",
      "json info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.json', 'size': 148, 'type': 'file', 'created': 1756889645.1912436, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1912436, 'ino': 3377699722055243, 'nlink': 1}\n",
      "yaml info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.yaml', 'size': 159, 'type': 'file', 'created': 1756889645.1912436, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1951694, 'ino': 1970324838501964, 'nlink': 1}\n",
      "yml info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.yml', 'size': 159, 'type': 'file', 'created': 1756889645.1951694, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.196516, 'ino': 5629499535740465, 'nlink': 1}\n",
      "arrow info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.arrow', 'size': 2770, 'type': 'file', 'created': 1756889645.1982415, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.1992433, 'ino': 1688849861791317, 'nlink': 1}\n",
      "feather info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.feather', 'size': 2770, 'type': 'file', 'created': 1756889645.204131, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.2053895, 'ino': 2814749768633956, 'nlink': 1}\n",
      "parquet info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.parquet', 'size': 2767, 'type': 'file', 'created': 1756889645.201695, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.2035718, 'ino': 2814749768633949, 'nlink': 1}\n",
      "pickle info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.pickle', 'size': 861, 'type': 'file', 'created': 1756889645.2002861, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.2002861, 'ino': 2533274791923291, 'nlink': 1}\n",
      "pkl info: {'name': 'c:/Users/Lisa Tan/Desktop/Projects/utilities/examples/logger/test_files/test.pkl', 'size': 861, 'type': 'file', 'created': 1756889645.2002861, 'islink': False, 'mode': 33206, 'uid': 0, 'gid': 0, 'mtime': 1756889645.2002861, 'ino': 2814749768633948, 'nlink': 1}\n"
     ]
    }
   ],
   "source": [
    "for f_type in file_types:\n",
    "    path = f\"./test_files/test.{f_type}\"\n",
    "\n",
    "    # Info\n",
    "    print(f\"{f_type} info:\", file_io.finfo(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv read: <class 'pandas.core.frame.DataFrame'>\n",
      "txt read: <class 'str'>\n",
      "text read: <class 'str'>\n",
      "log read: <class 'str'>\n",
      "sql read: <class 'str'>\n",
      "json read: <class 'list'>\n",
      "yaml read: <class 'list'>\n",
      "yml read: <class 'list'>\n",
      "arrow read: <class 'pandas.core.frame.DataFrame'>\n",
      "feather read: <class 'pandas.core.frame.DataFrame'>\n",
      "parquet read: <class 'pandas.core.frame.DataFrame'>\n",
      "pickle read: <class 'pandas.core.frame.DataFrame'>\n",
      "pkl read: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "for f_type in file_types:\n",
    "    path = f\"./test_files/test.{f_type}\"\n",
    "\n",
    "    # Read\n",
    "    data = file_io.fread(path)\n",
    "    print(f\"{f_type} read:\", type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2be21b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv written to copy: True\n",
      "txt written to copy: True\n",
      "text written to copy: True\n",
      "log written to copy: True\n",
      "sql written to copy: True\n",
      "json written to copy: True\n",
      "yaml written to copy: True\n",
      "yml written to copy: True\n",
      "arrow written to copy: True\n",
      "feather written to copy: True\n",
      "parquet written to copy: True\n",
      "pickle written to copy: True\n",
      "pkl written to copy: True\n"
     ]
    }
   ],
   "source": [
    "for f_type in file_types:\n",
    "    path = f\"./test_files/test.{f_type}\"\n",
    "    copy_path = f\"./test_files/test_copy.{f_type}\"\n",
    "\n",
    "    data = file_io.fread(path)\n",
    "    # Only write if the type matches the file type requirements\n",
    "    if f_type in [\"txt\", \"text\", \"log\", \"sql\"]:\n",
    "        if isinstance(data, str):\n",
    "            file_io.fwrite(copy_path, data)\n",
    "    elif f_type in [\"csv\", \"feather\", \"parquet\", \"arrow\"]:\n",
    "        if hasattr(data, \"to_csv\") or hasattr(data, \"to_parquet\"):\n",
    "            file_io.fwrite(copy_path, data)\n",
    "    else:\n",
    "        file_io.fwrite(copy_path, data)\n",
    "    print(f\"{f_type} written to copy:\", file_io.fexists(copy_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6468f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv copied to fcopy: True\n",
      "txt copied to fcopy: True\n",
      "text copied to fcopy: True\n",
      "log copied to fcopy: True\n",
      "sql copied to fcopy: True\n",
      "json copied to fcopy: True\n",
      "yaml copied to fcopy: True\n",
      "yml copied to fcopy: True\n",
      "arrow copied to fcopy: True\n",
      "feather copied to fcopy: True\n",
      "parquet copied to fcopy: True\n",
      "pickle copied to fcopy: True\n",
      "pkl copied to fcopy: True\n"
     ]
    }
   ],
   "source": [
    "for f_type in file_types:\n",
    "    path = f\"./test_files/test.{f_type}\"\n",
    "    fcopy_path = f\"./test_files/test_fcopy.{f_type}\"\n",
    "\n",
    "    # Copy\n",
    "    file_io.fcopy(path, fcopy_path)\n",
    "    print(f\"{f_type} copied to fcopy:\", file_io.fexists(fcopy_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27be6adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv deleted from copy: True\n",
      "csv deleted from fcopy: True\n",
      "txt deleted from copy: True\n",
      "txt deleted from fcopy: True\n",
      "text deleted from copy: True\n",
      "text deleted from fcopy: True\n",
      "log deleted from copy: True\n",
      "log deleted from fcopy: True\n",
      "sql deleted from copy: True\n",
      "sql deleted from fcopy: True\n",
      "json deleted from copy: True\n",
      "json deleted from fcopy: True\n",
      "yaml deleted from copy: True\n",
      "yaml deleted from fcopy: True\n",
      "yml deleted from copy: True\n",
      "yml deleted from fcopy: True\n",
      "arrow deleted from copy: True\n",
      "arrow deleted from fcopy: True\n",
      "feather deleted from copy: True\n",
      "feather deleted from fcopy: True\n",
      "parquet deleted from copy: True\n",
      "parquet deleted from fcopy: True\n",
      "pickle deleted from copy: True\n",
      "pickle deleted from fcopy: True\n",
      "pkl deleted from copy: True\n",
      "pkl deleted from fcopy: True\n"
     ]
    }
   ],
   "source": [
    "for f_type in file_types:\n",
    "    path = f\"./test_files/test.{f_type}\"\n",
    "    copy_path = f\"./test_files/test_copy.{f_type}\"\n",
    "    fcopy_path = f\"./test_files/test_fcopy.{f_type}\"\n",
    "\n",
    "    # Delete\n",
    "    file_io.fdelete(copy_path)\n",
    "    print(f\"{f_type} deleted from copy:\", not file_io.fexists(copy_path))\n",
    "    file_io.fdelete(fcopy_path)\n",
    "    print(f\"{f_type} deleted from fcopy:\", not file_io.fexists(fcopy_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa141d85",
   "metadata": {},
   "source": [
    "#### Clean up test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7756e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = os.path.dirname(path)\n",
    "file_io.fdelete(parent_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
